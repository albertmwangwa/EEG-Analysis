{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": "# EEG Analysis Project"
  },
  {
   "cell_type": "code",
   "id": "9847b3bbf9c2442f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T11:11:11.623886Z",
     "start_time": "2025-05-20T11:11:11.186093Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the dataset including the first three rows\n",
    "raw_eeg = pd.read_csv('Data/In Data.csv', header=None, low_memory=False)\n",
    "\n",
    "# Step 2: Extract the three header rows\n",
    "header1 = raw_eeg.iloc[0]  # First row: FFT Bands\n",
    "header2 = raw_eeg.iloc[1]  # Second row: Frequencies\n",
    "header3 = raw_eeg.iloc[2]  # Third row: Time format note (mainly first column)\n",
    "\n",
    "# Step 3: Build new headers\n",
    "new_columns = []\n",
    "\n",
    "for col in range(len(header1)):\n",
    "    if col == 0:\n",
    "        # First column is Time\n",
    "        new_columns.append('Time')\n",
    "    else:\n",
    "        # Concatenate: Band + \"_\" + Frequency\n",
    "        new_header = f\"{header1[col]}_{header2[col]}\"\n",
    "        new_columns.append(new_header)\n",
    "\n",
    "# Step 4: Assign the new headers & clean data\n",
    "clean_eeg = raw_eeg.iloc[3:].copy()  # Drop the first three rows\n",
    "clean_eeg.columns = new_columns      # Assign the new combined header\n",
    "clean_eeg.reset_index(drop=True, inplace=True)  # Reset index\n",
    "\n",
    "# Step 5: Convert signal columns to numeric\n",
    "for col in clean_eeg.columns[1:]:  # Skip 'Time'\n",
    "    clean_eeg[col] = pd.to_numeric(clean_eeg[col], errors='coerce')\n",
    "\n",
    "# Final check\n",
    "print(clean_eeg.info())\n",
    "print(clean_eeg.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18638 entries, 0 to 18637\n",
      "Data columns (total 41 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Time        18638 non-null  object \n",
      " 1   Delta_'F3'  18638 non-null  float64\n",
      " 2   Delta_'Fz'  18638 non-null  float64\n",
      " 3   Delta_'F4'  18638 non-null  float64\n",
      " 4   Delta_'C3'  18638 non-null  float64\n",
      " 5   Delta_'C4'  18638 non-null  float64\n",
      " 6   Delta_'Pz'  18638 non-null  float64\n",
      " 7   Delta_'O1'  18638 non-null  float64\n",
      " 8   Delta_'O2'  18638 non-null  float64\n",
      " 9   Theta_'F3'  18638 non-null  float64\n",
      " 10  Theta_'Fz'  18638 non-null  float64\n",
      " 11  Theta_'F4'  18638 non-null  float64\n",
      " 12  Theta_'C3'  18638 non-null  float64\n",
      " 13  Theta_'C4'  18638 non-null  float64\n",
      " 14  Theta_'Pz'  18638 non-null  float64\n",
      " 15  Theta_'O1'  18638 non-null  float64\n",
      " 16  Theta_'O2'  18638 non-null  float64\n",
      " 17  Alpha_'F3'  18638 non-null  float64\n",
      " 18  Alpha_'Fz'  18638 non-null  float64\n",
      " 19  Alpha_'F4'  18638 non-null  float64\n",
      " 20  Alpha_'C3'  18638 non-null  float64\n",
      " 21  Alpha_'C4'  18638 non-null  float64\n",
      " 22  Alpha_'Pz'  18638 non-null  float64\n",
      " 23  Alpha_'O1'  18638 non-null  float64\n",
      " 24  Alpha_'O2'  18638 non-null  float64\n",
      " 25  Beta_'F3'   18638 non-null  float64\n",
      " 26  Beta_'Fz'   18638 non-null  float64\n",
      " 27  Beta_'F4'   18638 non-null  float64\n",
      " 28  Beta_'C3'   18638 non-null  float64\n",
      " 29  Beta_'C4'   18638 non-null  float64\n",
      " 30  Beta_'Pz'   18638 non-null  float64\n",
      " 31  Beta_'O1'   18638 non-null  float64\n",
      " 32  Beta_'O2'   18638 non-null  float64\n",
      " 33  Gamma_'F3'  18638 non-null  float64\n",
      " 34  Gamma_'Fz'  18638 non-null  float64\n",
      " 35  Gamma_'F4'  18638 non-null  float64\n",
      " 36  Gamma_'C3'  18638 non-null  float64\n",
      " 37  Gamma_'C4'  18638 non-null  float64\n",
      " 38  Gamma_'Pz'  18638 non-null  float64\n",
      " 39  Gamma_'O1'  18638 non-null  float64\n",
      " 40  Gamma_'O2'  18638 non-null  float64\n",
      "dtypes: float64(40), object(1)\n",
      "memory usage: 5.8+ MB\n",
      "None\n",
      "                          Time  Delta_'F3'  Delta_'Fz'  Delta_'F4'  \\\n",
      "0  '[15:09:01.370 31/03/2023]'        3.06        4.40        5.70   \n",
      "1  '[15:09:01.385 31/03/2023]'        3.16        4.30        5.74   \n",
      "2  '[15:09:01.401 31/03/2023]'        3.24        4.35        5.77   \n",
      "3  '[15:09:01.418 31/03/2023]'        3.17        4.51        5.82   \n",
      "4  '[15:09:01.436 31/03/2023]'        3.10        4.33        5.87   \n",
      "\n",
      "   Delta_'C3'  Delta_'C4'  Delta_'Pz'  Delta_'O1'  Delta_'O2'  Theta_'F3'  \\\n",
      "0        4.17        2.22        4.88        7.27        7.83       10.68   \n",
      "1        3.94        2.31        4.79        7.07        7.55       10.49   \n",
      "2        3.84        2.30        4.82        6.88        7.45       10.31   \n",
      "3        3.75        2.29        4.86        7.22        7.37       10.15   \n",
      "4        3.59        2.19        4.94        7.54        7.33       10.00   \n",
      "\n",
      "   ...  Beta_'O1'  Beta_'O2'  Gamma_'F3'  Gamma_'Fz'  Gamma_'F4'  Gamma_'C3'  \\\n",
      "0  ...      19.96      17.69        0.31        1.21        1.56        1.43   \n",
      "1  ...      19.02      18.47        0.31        1.22        1.50        1.37   \n",
      "2  ...      18.69      19.48        0.31        1.20        1.44        1.37   \n",
      "3  ...      19.51      20.42        0.30        1.20        1.36        1.38   \n",
      "4  ...      20.27      21.40        0.31        1.17        1.30        1.37   \n",
      "\n",
      "   Gamma_'C4'  Gamma_'Pz'  Gamma_'O1'  Gamma_'O2'  \n",
      "0        0.65        1.41        1.76        1.27  \n",
      "1        0.65        1.41        1.84        1.27  \n",
      "2        0.64        1.38        1.92        1.26  \n",
      "3        0.63        1.35        1.94        1.27  \n",
      "4        0.60        1.33        1.95        1.27  \n",
      "\n",
      "[5 rows x 41 columns]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46ad9d9ba31f3148",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T06:27:26.850465Z",
     "start_time": "2025-04-16T06:27:26.815551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Delta_'F3'</th>\n",
       "      <th>Delta_'Fz'</th>\n",
       "      <th>Delta_'F4'</th>\n",
       "      <th>Delta_'C3'</th>\n",
       "      <th>Delta_'C4'</th>\n",
       "      <th>Delta_'Pz'</th>\n",
       "      <th>Delta_'O1'</th>\n",
       "      <th>Delta_'O2'</th>\n",
       "      <th>Theta_'F3'</th>\n",
       "      <th>...</th>\n",
       "      <th>Beta_'O1'</th>\n",
       "      <th>Beta_'O2'</th>\n",
       "      <th>Gamma_'F3'</th>\n",
       "      <th>Gamma_'Fz'</th>\n",
       "      <th>Gamma_'F4'</th>\n",
       "      <th>Gamma_'C3'</th>\n",
       "      <th>Gamma_'C4'</th>\n",
       "      <th>Gamma_'Pz'</th>\n",
       "      <th>Gamma_'O1'</th>\n",
       "      <th>Gamma_'O2'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4363</th>\n",
       "      <td>'[15:10:14.077 31/03/2023]'</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.49</td>\n",
       "      <td>...</td>\n",
       "      <td>3.19</td>\n",
       "      <td>7.12</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>'[15:09:36.782 31/03/2023]'</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.14</td>\n",
       "      <td>...</td>\n",
       "      <td>1.91</td>\n",
       "      <td>11.25</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5240</th>\n",
       "      <td>'[15:10:28.693 31/03/2023]'</td>\n",
       "      <td>0.58</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.61</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.94</td>\n",
       "      <td>6.62</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5845</th>\n",
       "      <td>'[15:10:38.775 31/03/2023]'</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0.91</td>\n",
       "      <td>2.41</td>\n",
       "      <td>2.36</td>\n",
       "      <td>...</td>\n",
       "      <td>1.64</td>\n",
       "      <td>22.02</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6254</th>\n",
       "      <td>'[15:10:45.592 31/03/2023]'</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3561</th>\n",
       "      <td>'[15:10:00.713 31/03/2023]'</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.81</td>\n",
       "      <td>...</td>\n",
       "      <td>3.36</td>\n",
       "      <td>9.54</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221</th>\n",
       "      <td>'[15:11:01.707 31/03/2023]'</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.37</td>\n",
       "      <td>...</td>\n",
       "      <td>6.65</td>\n",
       "      <td>7.34</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10896</th>\n",
       "      <td>'[15:12:02.950 31/03/2023]'</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.18</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1.15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.29</td>\n",
       "      <td>7.09</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17412</th>\n",
       "      <td>'[15:13:51.540 31/03/2023]'</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.08</td>\n",
       "      <td>...</td>\n",
       "      <td>2.19</td>\n",
       "      <td>8.10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>'[15:09:31.198 31/03/2023]'</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.60</td>\n",
       "      <td>...</td>\n",
       "      <td>6.18</td>\n",
       "      <td>5.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Time  Delta_'F3'  Delta_'Fz'  Delta_'F4'  \\\n",
       "4363   '[15:10:14.077 31/03/2023]'        0.42        1.07        0.62   \n",
       "2125   '[15:09:36.782 31/03/2023]'        0.33        0.68        0.56   \n",
       "5240   '[15:10:28.693 31/03/2023]'        0.58        2.12        0.65   \n",
       "5845   '[15:10:38.775 31/03/2023]'        0.46        1.37        0.73   \n",
       "6254   '[15:10:45.592 31/03/2023]'        0.17        0.20        0.18   \n",
       "3561   '[15:10:00.713 31/03/2023]'        0.31        1.35        0.52   \n",
       "7221   '[15:11:01.707 31/03/2023]'        0.43        1.01        1.59   \n",
       "10896  '[15:12:02.950 31/03/2023]'        0.21        1.28        0.46   \n",
       "17412  '[15:13:51.540 31/03/2023]'        0.30        0.62        0.63   \n",
       "1790   '[15:09:31.198 31/03/2023]'        0.35        0.35        0.29   \n",
       "\n",
       "       Delta_'C3'  Delta_'C4'  Delta_'Pz'  Delta_'O1'  Delta_'O2'  Theta_'F3'  \\\n",
       "4363         1.66        0.36        0.93        0.52        0.68        1.49   \n",
       "2125         0.66        0.42        0.63        0.31        1.12        1.14   \n",
       "5240         1.25        0.61        2.16        0.56        1.35        2.02   \n",
       "5845         1.69        0.48        1.51        0.91        2.41        2.36   \n",
       "6254         0.30        0.17        0.13        0.28        0.28        0.63   \n",
       "3561         1.45        0.26        2.25        0.28        0.70        0.81   \n",
       "7221         1.65        0.52        1.22        1.50        1.67        1.37   \n",
       "10896        1.81        0.14        0.71        0.18        2.17        1.15   \n",
       "17412        1.07        0.33        0.39        0.38        1.05        2.08   \n",
       "1790         0.41        0.32        0.38        0.42        0.43        0.60   \n",
       "\n",
       "       ...  Beta_'O1'  Beta_'O2'  Gamma_'F3'  Gamma_'Fz'  Gamma_'F4'  \\\n",
       "4363   ...       3.19       7.12        0.11        0.28        0.13   \n",
       "2125   ...       1.91      11.25        0.08        0.27        0.12   \n",
       "5240   ...       1.94       6.62        0.10        0.83        0.16   \n",
       "5845   ...       1.64      22.02        0.10        0.42        0.19   \n",
       "6254   ...       3.60       1.53        0.11        0.11        0.09   \n",
       "3561   ...       3.36       9.54        0.08        0.44        0.12   \n",
       "7221   ...       6.65       7.34        0.13        0.26        0.56   \n",
       "10896  ...       1.29       7.09        0.12        0.47        0.18   \n",
       "17412  ...       2.19       8.10        0.08        0.14        0.17   \n",
       "1790   ...       6.18       5.05        0.14        0.11        0.11   \n",
       "\n",
       "       Gamma_'C3'  Gamma_'C4'  Gamma_'Pz'  Gamma_'O1'  Gamma_'O2'  \n",
       "4363         0.39        0.08        0.26        0.14        0.22  \n",
       "2125         0.10        0.11        0.15        0.09        0.44  \n",
       "5240         0.24        0.10        0.71        0.12        0.26  \n",
       "5845         0.36        0.09        0.57        0.12        0.61  \n",
       "6254         0.17        0.09        0.12        0.16        0.12  \n",
       "3561         0.40        0.07        0.65        0.15        0.49  \n",
       "7221         0.56        0.12        0.30        0.46        0.43  \n",
       "10896        0.49        0.13        0.42        0.14        0.51  \n",
       "17412        0.22        0.10        0.14        0.15        0.27  \n",
       "1790         0.13        0.11        0.14        0.18        0.15  \n",
       "\n",
       "[10 rows x 41 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_eeg.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c51db362ce3e7a",
   "metadata": {},
   "source": [
    "Handling Time Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "526df80cf7b24fc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T06:30:14.819590Z",
     "start_time": "2025-04-16T06:30:14.701764Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Delta_'F3'</th>\n",
       "      <th>Delta_'Fz'</th>\n",
       "      <th>Delta_'F4'</th>\n",
       "      <th>Delta_'C3'</th>\n",
       "      <th>Delta_'C4'</th>\n",
       "      <th>Delta_'Pz'</th>\n",
       "      <th>Delta_'O1'</th>\n",
       "      <th>Delta_'O2'</th>\n",
       "      <th>Theta_'F3'</th>\n",
       "      <th>...</th>\n",
       "      <th>Beta_'O1'</th>\n",
       "      <th>Beta_'O2'</th>\n",
       "      <th>Gamma_'F3'</th>\n",
       "      <th>Gamma_'Fz'</th>\n",
       "      <th>Gamma_'F4'</th>\n",
       "      <th>Gamma_'C3'</th>\n",
       "      <th>Gamma_'C4'</th>\n",
       "      <th>Gamma_'Pz'</th>\n",
       "      <th>Gamma_'O1'</th>\n",
       "      <th>Gamma_'O2'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12391</th>\n",
       "      <td>15:12:27.864</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.72</td>\n",
       "      <td>7.09</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10697</th>\n",
       "      <td>15:11:59.634</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.49</td>\n",
       "      <td>2.76</td>\n",
       "      <td>...</td>\n",
       "      <td>4.15</td>\n",
       "      <td>13.16</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3558</th>\n",
       "      <td>15:10:00.663</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.84</td>\n",
       "      <td>...</td>\n",
       "      <td>3.51</td>\n",
       "      <td>8.87</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>15:09:23.666</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.78</td>\n",
       "      <td>...</td>\n",
       "      <td>5.04</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>15:09:02.436</td>\n",
       "      <td>1.57</td>\n",
       "      <td>3.98</td>\n",
       "      <td>5.48</td>\n",
       "      <td>6.46</td>\n",
       "      <td>1.18</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.85</td>\n",
       "      <td>2.47</td>\n",
       "      <td>7.10</td>\n",
       "      <td>...</td>\n",
       "      <td>19.77</td>\n",
       "      <td>22.66</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10227</th>\n",
       "      <td>15:11:51.802</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.17</td>\n",
       "      <td>2.08</td>\n",
       "      <td>4.65</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.23</td>\n",
       "      <td>3.41</td>\n",
       "      <td>5.65</td>\n",
       "      <td>...</td>\n",
       "      <td>9.64</td>\n",
       "      <td>5.16</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15821</th>\n",
       "      <td>15:13:25.025</td>\n",
       "      <td>0.83</td>\n",
       "      <td>2.52</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.02</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.54</td>\n",
       "      <td>...</td>\n",
       "      <td>4.71</td>\n",
       "      <td>11.33</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12572</th>\n",
       "      <td>15:12:30.881</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.99</td>\n",
       "      <td>...</td>\n",
       "      <td>4.22</td>\n",
       "      <td>8.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8395</th>\n",
       "      <td>15:11:21.272</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.03</td>\n",
       "      <td>...</td>\n",
       "      <td>2.02</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17055</th>\n",
       "      <td>15:13:45.590</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.83</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2.66</td>\n",
       "      <td>2.32</td>\n",
       "      <td>...</td>\n",
       "      <td>2.08</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6941</th>\n",
       "      <td>15:10:57.041</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1.21</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.46</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.43</td>\n",
       "      <td>...</td>\n",
       "      <td>6.29</td>\n",
       "      <td>6.96</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13854</th>\n",
       "      <td>15:12:52.246</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.28</td>\n",
       "      <td>2.43</td>\n",
       "      <td>...</td>\n",
       "      <td>2.34</td>\n",
       "      <td>3.98</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12755</th>\n",
       "      <td>15:12:33.932</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.26</td>\n",
       "      <td>...</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8838</th>\n",
       "      <td>15:11:28.655</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.08</td>\n",
       "      <td>...</td>\n",
       "      <td>3.75</td>\n",
       "      <td>8.42</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3902</th>\n",
       "      <td>15:10:06.395</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>3.81</td>\n",
       "      <td>5.74</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15421</th>\n",
       "      <td>15:13:18.360</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12005</th>\n",
       "      <td>15:12:21.432</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.20</td>\n",
       "      <td>...</td>\n",
       "      <td>2.80</td>\n",
       "      <td>4.84</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12021</th>\n",
       "      <td>15:12:21.699</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.37</td>\n",
       "      <td>...</td>\n",
       "      <td>2.54</td>\n",
       "      <td>4.43</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5259</th>\n",
       "      <td>15:10:29.010</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>2.58</td>\n",
       "      <td>3.88</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16757</th>\n",
       "      <td>15:13:40.625</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.22</td>\n",
       "      <td>2.77</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1.09</td>\n",
       "      <td>2.97</td>\n",
       "      <td>6.90</td>\n",
       "      <td>...</td>\n",
       "      <td>11.95</td>\n",
       "      <td>17.37</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time  Delta_'F3'  Delta_'Fz'  Delta_'F4'  Delta_'C3'  \\\n",
       "12391  15:12:27.864        0.55        1.47        1.30        1.97   \n",
       "10697  15:11:59.634        0.41        0.79        0.89        1.68   \n",
       "3558   15:10:00.663        0.31        1.22        0.52        1.14   \n",
       "1338   15:09:23.666        0.24        0.27        0.24        0.55   \n",
       "64     15:09:02.436        1.57        3.98        5.48        6.46   \n",
       "10227  15:11:51.802        0.96        1.17        2.08        4.65   \n",
       "15821  15:13:25.025        0.83        2.52        1.44        1.60   \n",
       "12572  15:12:30.881        0.37        0.93        0.56        1.96   \n",
       "8395   15:11:21.272        0.13        0.38        0.39        0.69   \n",
       "17055  15:13:45.590        0.62        1.46        0.83        2.44   \n",
       "6941   15:10:57.041        0.20        1.47        1.21        1.27   \n",
       "13854  15:12:52.246        0.77        1.14        0.75        0.57   \n",
       "12755  15:12:33.932        0.24        0.30        0.27        0.21   \n",
       "8838   15:11:28.655        0.52        0.82        0.71        0.65   \n",
       "3902   15:10:06.395        0.25        0.70        0.28        0.78   \n",
       "15421  15:13:18.360        0.21        0.23        0.19        0.24   \n",
       "12005  15:12:21.432        0.18        0.41        0.35        0.33   \n",
       "12021  15:12:21.699        0.14        0.30        0.42        0.24   \n",
       "5259   15:10:29.010        0.43        1.02        0.44        1.02   \n",
       "16757  15:13:40.625        0.84        1.22        2.77        2.40   \n",
       "\n",
       "       Delta_'C4'  Delta_'Pz'  Delta_'O1'  Delta_'O2'  Theta_'F3'  ...  \\\n",
       "12391        0.66        1.47        0.83        1.61        2.05  ...   \n",
       "10697        0.39        1.09        0.60        1.49        2.76  ...   \n",
       "3558         0.27        2.07        0.32        0.70        0.84  ...   \n",
       "1338         0.27        0.30        0.33        0.62        0.78  ...   \n",
       "64           1.18        4.91        4.85        2.47        7.10  ...   \n",
       "10227        1.00        1.74        1.23        3.41        5.65  ...   \n",
       "15821        0.98        1.54        1.02        2.51        2.54  ...   \n",
       "12572        0.20        0.81        0.87        1.76        0.99  ...   \n",
       "8395         0.12        0.27        0.24        0.52        1.03  ...   \n",
       "17055        0.54        1.06        0.56        2.66        2.32  ...   \n",
       "6941         0.47        1.27        0.46        2.24        1.43  ...   \n",
       "13854        0.64        1.24        0.55        1.28        2.43  ...   \n",
       "12755        0.15        0.19        0.22        0.18        1.26  ...   \n",
       "8838         0.38        0.63        0.40        1.10        1.08  ...   \n",
       "3902         0.32        0.60        0.67        1.22        0.94  ...   \n",
       "15421        0.21        0.23        0.34        0.23        0.63  ...   \n",
       "12005        0.15        0.36        0.18        0.67        1.20  ...   \n",
       "12021        0.13        0.33        0.14        0.64        1.37  ...   \n",
       "5259         0.34        1.15        0.41        1.11        2.31  ...   \n",
       "16757        0.85        2.25        1.09        2.97        6.90  ...   \n",
       "\n",
       "       Beta_'O1'  Beta_'O2'  Gamma_'F3'  Gamma_'Fz'  Gamma_'F4'  Gamma_'C3'  \\\n",
       "12391       2.72       7.09        0.12        0.50        0.27        0.48   \n",
       "10697       4.15      13.16        0.13        0.24        0.28        0.43   \n",
       "3558        3.51       8.87        0.08        0.40        0.12        0.39   \n",
       "1338        5.04       4.26        0.11        0.12        0.10        0.17   \n",
       "64         19.77      22.66        0.27        1.02        1.58        1.33   \n",
       "10227       9.64       5.16        0.19        0.65        0.41        0.72   \n",
       "15821       4.71      11.33        0.19        0.96        0.20        0.42   \n",
       "12572       4.22       8.12        0.10        0.95        0.15        0.48   \n",
       "8395        2.02       2.81        0.13        0.20        0.10        0.21   \n",
       "17055       2.08       8.05        0.12        0.43        0.33        0.29   \n",
       "6941        6.29       6.96        0.16        0.48        0.35        0.36   \n",
       "13854       2.34       3.98        0.09        0.28        0.14        0.25   \n",
       "12755       3.76       2.75        0.10        0.12        0.10        0.11   \n",
       "8838        3.75       8.42        0.11        0.20        0.18        0.20   \n",
       "3902        3.81       5.74        0.09        0.21        0.16        0.24   \n",
       "15421       3.15       3.10        0.13        0.14        0.12        0.15   \n",
       "12005       2.80       4.84        0.06        0.11        0.14        0.20   \n",
       "12021       2.54       4.43        0.07        0.09        0.15        0.18   \n",
       "5259        2.58       3.88        0.10        0.36        0.13        0.27   \n",
       "16757      11.95      17.37        0.28        0.94        0.36        0.86   \n",
       "\n",
       "       Gamma_'C4'  Gamma_'Pz'  Gamma_'O1'  Gamma_'O2'  \n",
       "12391        0.08        0.39        0.14        0.58  \n",
       "10697        0.13        0.29        0.16        0.45  \n",
       "3558         0.07        0.61        0.15        0.49  \n",
       "1338         0.12        0.12        0.12        0.20  \n",
       "64           0.31        0.91        1.39        1.02  \n",
       "10227        0.17        0.58        0.28        0.43  \n",
       "15821        0.23        0.21        0.18        0.54  \n",
       "12572        0.10        0.64        0.27        0.33  \n",
       "8395         0.10        0.21        0.17        0.18  \n",
       "17055        0.13        0.24        0.21        0.39  \n",
       "6941         0.13        0.52        0.31        0.66  \n",
       "13854        0.08        0.22        0.11        0.27  \n",
       "12755        0.10        0.14        0.13        0.13  \n",
       "8838         0.11        0.16        0.18        0.43  \n",
       "3902         0.15        0.30        0.20        0.29  \n",
       "15421        0.13        0.15        0.13        0.13  \n",
       "12005        0.05        0.11        0.10        0.15  \n",
       "12021        0.05        0.11        0.11        0.19  \n",
       "5259         0.08        0.40        0.11        0.25  \n",
       "16757        0.30        0.60        0.44        0.53  \n",
       "\n",
       "[20 rows x 41 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Clean the Time column (remove square brackets and strip spaces)\n",
    "clean_eeg['Time'] = (\n",
    "    clean_eeg['Time']\n",
    "    .str.replace(r'[\\[\\]\\']', '', regex=True)          # Remove [ ] and ' characters\n",
    "    .str.replace(r'\\s*\\d{2}/\\d{2}/\\d{4}', '', regex=True)  # Remove date (e.g., 31/03/2023)\n",
    "    .str.strip()                                       # Remove any remaining whitespace\n",
    ")\n",
    "\n",
    "clean_eeg.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa15c3d62fb98da8",
   "metadata": {},
   "source": [
    "#### Determining Sampling Frequency useful in EDA for EEG Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c424c9ef34fccd25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T06:34:21.188723Z",
     "start_time": "2025-04-16T06:34:21.109790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Sampling Frequency: 60.01 Hz\n"
     ]
    }
   ],
   "source": [
    "# Convert Time back to timedelta in seconds for sampling estimation\n",
    "time_series = pd.to_datetime(clean_eeg['Time'].astype(str), format='%H:%M:%S.%f', errors='coerce')\n",
    "\n",
    "# Calculate average time difference in seconds\n",
    "time_diffs = time_series.diff().dropna().dt.total_seconds()\n",
    "sfreq = round(1 / time_diffs.mean(), 2)  # Average samples per second\n",
    "\n",
    "print(f\"Detected Sampling Frequency: {sfreq} Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "c62343d5918628c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T11:13:21.679064Z",
     "start_time": "2025-04-16T11:13:19.467961Z"
    }
   },
   "source": [
    "import mne\n",
    "# Prepare for MNE: Extract EEG data & metadata\n",
    "channel_names = clean_eeg.columns[1:].tolist()     # All columns except 'Time'\n",
    "channel_types = ['eeg'] * len(channel_names)\n",
    "\n",
    "# Transpose EEG data: shape must be [n_channels, n_samples]\n",
    "eeg_values = clean_eeg.iloc[:, 1:].T.values\n",
    "\n",
    "# Create MNE Info and RawArray\n",
    "info = mne.create_info(ch_names=channel_names, sfreq=sfreq, ch_types=channel_types)\n",
    "raw = mne.io.RawArray(eeg_values, info)\n",
    "\n",
    "# Plot EEG Overview\n",
    "raw.plot(n_channels=min(20, len(channel_names)), scalings='auto', title='EEG Raw Data Overview')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=40, n_times=18638\n",
      "    Range : 0 ... 18637 =      0.000 ...   310.565 secs\n",
      "Ready.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne_qt_browser._pg_figure.MNEQtBrowser at 0x2d73e7e2450>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "id": "6c59ff05f66b685d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T11:15:51.154075Z",
     "start_time": "2025-04-16T11:15:51.122988Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "# Prepare data for MNE\n",
    "channel_names = clean_eeg.columns[1].tolist() # 'FFT Bands'\n",
    "channel_types = ['eeg'] * len(channel_names)\n",
    "eeg_values = clean_eeg.iloc[:, 1:].T.values\n",
    "\n",
    "# Sampling frequency assumption\n",
    "sfreq = 128.0  \n",
    "\n",
    "# Create MNE Info & RawArray\n",
    "info = mne.create_info(ch_names=channel_names, sfreq=sfreq, ch_types=channel_types)\n",
    "raw = mne.io.RawArray(eeg_values, info)\n",
    "\n",
    "# Plot EEG overview\n",
    "raw.plot(n_channels=20, scalings='auto', title='EEG Raw Data Overview')\n"
   ],
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[49], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmne\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Prepare data for MNE\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m channel_names \u001B[38;5;241m=\u001B[39m clean_eeg\u001B[38;5;241m.\u001B[39mcolumns[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mtolist() \u001B[38;5;66;03m# 'FFT Bands'\u001B[39;00m\n\u001B[0;32m      6\u001B[0m channel_types \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124meeg\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mlen\u001B[39m(channel_names)\n\u001B[0;32m      7\u001B[0m eeg_values \u001B[38;5;241m=\u001B[39m clean_eeg\u001B[38;5;241m.\u001B[39miloc[:, \u001B[38;5;241m1\u001B[39m:]\u001B[38;5;241m.\u001B[39mT\u001B[38;5;241m.\u001B[39mvalues\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'str' object has no attribute 'tolist'"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "id": "5f7d241847727503",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T11:17:42.521546Z",
     "start_time": "2025-04-16T11:16:43.368293Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming 'clean_eeg_data' from previous step\n",
    "# Convert timestamp to datetime if needed\n",
    "clean_eeg_data['Time'] = pd.to_datetime(clean_eeg_data[\"'FFT Bands'\"].str.replace('[\\[\\]]', '', regex=True), errors='coerce')\n",
    "\n",
    "# Plot: Histogram for each band type\n",
    "band_prefixes = ['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma']\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "for idx, band in enumerate(band_prefixes):\n",
    "    plt.subplot(2, 3, idx + 1)\n",
    "    band_columns = [col for col in clean_eeg_data.columns if col.startswith(band)]\n",
    "    sns.histplot(clean_eeg_data[band_columns].values.flatten(), bins=100, kde=True)\n",
    "    plt.title(f'{band} Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation Matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "corr = clean_eeg_data.iloc[:, 1:].corr()  # skip timestamp\n",
    "sns.heatmap(corr, cmap='coolwarm', center=0, square=True)\n",
    "plt.title('Correlation Matrix of EEG Features')\n",
    "plt.show()\n",
    "\n",
    "# Time Series Plot for selected bands\n",
    "plt.figure(figsize=(14, 6))\n",
    "sample_columns = ['Alpha', 'Beta', 'Theta', 'Gamma', 'Delta']\n",
    "for band in sample_columns:\n",
    "    band_cols = [col for col in clean_eeg_data.columns if col.startswith(band)]\n",
    "    plt.plot(clean_eeg_data['Time'], clean_eeg_data[band_cols].mean(axis=1), label=band)\n",
    "plt.legend()\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Average Band Power')\n",
    "plt.title('EEG Band Power Over Time')\n",
    "plt.show()\n",
    "\n",
    "# Boxplots: Detect Outliers\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.boxplot(data=clean_eeg_data.iloc[:, 1:], orient='h')\n",
    "plt.title('EEG Feature Distribution & Outliers')\n",
    "plt.show()\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\['\n",
      "C:\\Users\\DALEI\\AppData\\Local\\Temp\\ipykernel_43692\\2156914266.py:7: SyntaxWarning: invalid escape sequence '\\['\n",
      "  clean_eeg_data['Time'] = pd.to_datetime(clean_eeg_data[\"'FFT Bands'\"].str.replace('[\\[\\]]', '', regex=True), errors='coerce')\n",
      "C:\\Users\\DALEI\\AppData\\Local\\Temp\\ipykernel_43692\\2156914266.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  clean_eeg_data['Time'] = pd.to_datetime(clean_eeg_data[\"'FFT Bands'\"].str.replace('[\\[\\]]', '', regex=True), errors='coerce')\n",
      "C:\\Users\\DALEI\\AppData\\Local\\Temp\\ipykernel_43692\\2156914266.py:7: SyntaxWarning: invalid escape sequence '\\['\n",
      "  clean_eeg_data['Time'] = pd.to_datetime(clean_eeg_data[\"'FFT Bands'\"].str.replace('[\\[\\]]', '', regex=True), errors='coerce')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: \"'F3'\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[50], line 23\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# Correlation Matrix\u001B[39;00m\n\u001B[0;32m     22\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m12\u001B[39m, \u001B[38;5;241m10\u001B[39m))\n\u001B[1;32m---> 23\u001B[0m corr \u001B[38;5;241m=\u001B[39m clean_eeg_data\u001B[38;5;241m.\u001B[39miloc[:, \u001B[38;5;241m1\u001B[39m:]\u001B[38;5;241m.\u001B[39mcorr()  \u001B[38;5;66;03m# skip timestamp\u001B[39;00m\n\u001B[0;32m     24\u001B[0m sns\u001B[38;5;241m.\u001B[39mheatmap(corr, cmap\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcoolwarm\u001B[39m\u001B[38;5;124m'\u001B[39m, center\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, square\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     25\u001B[0m plt\u001B[38;5;241m.\u001B[39mtitle(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCorrelation Matrix of EEG Features\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11049\u001B[0m, in \u001B[0;36mDataFrame.corr\u001B[1;34m(self, method, min_periods, numeric_only)\u001B[0m\n\u001B[0;32m  11047\u001B[0m cols \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mcolumns\n\u001B[0;32m  11048\u001B[0m idx \u001B[38;5;241m=\u001B[39m cols\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m> 11049\u001B[0m mat \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto_numpy(dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mfloat\u001B[39m, na_value\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mnan, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m  11051\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpearson\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m  11052\u001B[0m     correl \u001B[38;5;241m=\u001B[39m libalgos\u001B[38;5;241m.\u001B[39mnancorr(mat, minp\u001B[38;5;241m=\u001B[39mmin_periods)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py:1993\u001B[0m, in \u001B[0;36mDataFrame.to_numpy\u001B[1;34m(self, dtype, copy, na_value)\u001B[0m\n\u001B[0;32m   1991\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1992\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdtype(dtype)\n\u001B[1;32m-> 1993\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mgr\u001B[38;5;241m.\u001B[39mas_array(dtype\u001B[38;5;241m=\u001B[39mdtype, copy\u001B[38;5;241m=\u001B[39mcopy, na_value\u001B[38;5;241m=\u001B[39mna_value)\n\u001B[0;32m   1994\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m dtype:\n\u001B[0;32m   1995\u001B[0m     result \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(result, dtype\u001B[38;5;241m=\u001B[39mdtype)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1694\u001B[0m, in \u001B[0;36mBlockManager.as_array\u001B[1;34m(self, dtype, copy, na_value)\u001B[0m\n\u001B[0;32m   1692\u001B[0m         arr\u001B[38;5;241m.\u001B[39mflags\u001B[38;5;241m.\u001B[39mwriteable \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m   1693\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1694\u001B[0m     arr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_interleave(dtype\u001B[38;5;241m=\u001B[39mdtype, na_value\u001B[38;5;241m=\u001B[39mna_value)\n\u001B[0;32m   1695\u001B[0m     \u001B[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001B[39;00m\n\u001B[0;32m   1696\u001B[0m     \u001B[38;5;66;03m# to further copy if copy=True or setting na_value\u001B[39;00m\n\u001B[0;32m   1698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m na_value \u001B[38;5;129;01mis\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mno_default:\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1753\u001B[0m, in \u001B[0;36mBlockManager._interleave\u001B[1;34m(self, dtype, na_value)\u001B[0m\n\u001B[0;32m   1751\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1752\u001B[0m         arr \u001B[38;5;241m=\u001B[39m blk\u001B[38;5;241m.\u001B[39mget_values(dtype)\n\u001B[1;32m-> 1753\u001B[0m     result[rl\u001B[38;5;241m.\u001B[39mindexer] \u001B[38;5;241m=\u001B[39m arr\n\u001B[0;32m   1754\u001B[0m     itemmask[rl\u001B[38;5;241m.\u001B[39mindexer] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1756\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m itemmask\u001B[38;5;241m.\u001B[39mall():\n",
      "\u001B[1;31mValueError\u001B[0m: could not convert string to float: \"'F3'\""
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "\n",
    "# Make sure your 'Time' column is properly converted to datetime first!\n",
    "clean_eeg_data['Time'] = pd.to_datetime(clean_eeg_data['Time'], errors='coerce')\n",
    "\n",
    "# Drop rows with invalid timestamps\n",
    "clean_eeg_data = clean_eeg_data.dropna(subset=['Time']).reset_index(drop=True)\n",
    "\n",
    "# Standardize EEG data (skip timestamp column)\n",
    "X = clean_eeg_data.iloc[:, 1:].drop(columns=['Cluster'], errors='ignore').values  # exclude 'Cluster' if rerunning\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Dimensionality Reduction with PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Plot PCA Components\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], alpha=0.4)\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.title('EEG Signal: PCA Projection')\n",
    "plt.show()\n",
    "\n",
    "# Apply KMeans Clustering (let’s assume 3 cognitive states as a start)\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Plot Clusters\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=clusters, palette='tab10')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.title('EEG Brain Activity Clusters')\n",
    "plt.legend(title='Cluster')\n",
    "plt.show()\n",
    "\n",
    "# Assign clusters to original data\n",
    "clean_eeg_data['Cluster'] = clusters\n",
    "\n",
    "# Plot Clustered Brain Activity Over Time\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(clean_eeg_data['Time'], clean_eeg_data['Cluster'], linestyle='-', marker='.', alpha=0.7)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Detected Brain State Cluster')\n",
    "plt.title('EEG Brain State Evolution Over Time')\n",
    "\n",
    "# Format the x-axis to display readable time\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.show()\n"
   ],
   "id": "e3a8b3d3614d3c14"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Classification with SVM\n",
    "# Now we'll implement SVM classification using the clusters as proxy labels\n"
   ],
   "id": "bae34496feb9b149"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ensure we're using the correct dataframe\n",
    "# If clean_eeg_data doesn't exist, create it from clean_eeg\n",
    "try:\n",
    "    # Check if clean_eeg_data exists\n",
    "    clean_eeg_data.head()\n",
    "except NameError:\n",
    "    # If not, create it from clean_eeg\n",
    "    clean_eeg_data = clean_eeg.copy()\n",
    "    # Make sure it has the Cluster column from the previous section\n",
    "    if 'Cluster' not in clean_eeg_data.columns:\n",
    "        print(\"Warning: Cluster column not found. Please run the clustering section first.\")\n",
    "\n",
    "# Prepare the data for classification\n",
    "# X: features (EEG data), y: target (clusters)\n",
    "X = clean_eeg_data.iloc[:, 1:-1].values  # All columns except Time and Cluster\n",
    "y = clean_eeg_data['Cluster'].values     # Cluster column as target\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline with preprocessing and SVM\n",
    "svm_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Standardize features\n",
    "    ('svm', SVC(kernel='rbf', probability=True))  # SVM with RBF kernel\n",
    "])\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'svm__C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'svm__gamma': ['scale', 'auto', 0.1, 0.01]  # Kernel coefficient\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    svm_pipeline, \n",
    "    param_grid, \n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training SVM model with grid search...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nModel Evaluation on Test Set:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Plot decision regions (for 2D visualization using PCA)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA to reduce dimensions to 2 for visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Split PCA-transformed data\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(\n",
    "    X_pca, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train a new SVM on the PCA-transformed data\n",
    "svm_pca = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC(kernel='rbf', **grid_search.best_params_))\n",
    "])\n",
    "svm_pca.fit(X_train_pca, y_train_pca)\n",
    "\n",
    "# Create a mesh grid for decision boundary visualization\n",
    "def plot_decision_boundary(X, y, model, title):\n",
    "    h = 0.02  # Step size in the mesh\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "    # Make predictions on the mesh grid\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot the decision boundary\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap='coolwarm')\n",
    "\n",
    "    # Plot the data points\n",
    "    scatter = plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap='coolwarm')\n",
    "    plt.xlabel('PCA Component 1')\n",
    "    plt.ylabel('PCA Component 2')\n",
    "    plt.title(title)\n",
    "    plt.colorbar(scatter, label='Cluster')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot decision boundary\n",
    "plot_decision_boundary(X_pca, y, svm_pca, 'SVM Decision Boundaries (PCA)')\n"
   ],
   "id": "c37fca7ef0d9f4a6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature Importance Analysis\n",
   "id": "749a75badec30294"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Analyze feature importance using SVM coefficients (for linear kernel) or permutation importance\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# For non-linear kernels like RBF, we use permutation importance\n",
    "result = permutation_importance(\n",
    "    best_model, X_test, y_test, \n",
    "    n_repeats=10, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Get feature names\n",
    "feature_names = clean_eeg_data.columns[1:-1].tolist()\n",
    "\n",
    "# Create a DataFrame with feature importances\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': result.importances_mean\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot top 20 features\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df.head(20))\n",
    "plt.title('Top 20 EEG Features by Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "39fc289881a74237"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Cross-Validation Performance\n",
   "id": "dba68c8fc31fbbb2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(best_model, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation results\n",
    "print(\"Cross-Validation Results:\")\n",
    "print(f\"Mean Accuracy: {cv_scores.mean():.4f}\")\n",
    "print(f\"Standard Deviation: {cv_scores.std():.4f}\")\n",
    "print(f\"Individual Fold Scores: {cv_scores}\")\n",
    "\n",
    "# Plot cross-validation scores\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(range(1, 6), cv_scores, color='skyblue')\n",
    "plt.axhline(y=cv_scores.mean(), color='red', linestyle='--', label=f'Mean Accuracy: {cv_scores.mean():.4f}')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('5-Fold Cross-Validation Accuracy')\n",
    "plt.xticks(range(1, 6))\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "bde54d56d90531c5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Additional Classification Models\n",
    "# Now we'll implement and compare multiple classification models as requested\n"
   ],
   "id": "759f3527dcf04337"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Ensure we're using the correct dataframe\n",
    "try:\n",
    "    # Check if clean_eeg_data exists\n",
    "    clean_eeg_data.head()\n",
    "except NameError:\n",
    "    # If not, create it from clean_eeg\n",
    "    clean_eeg_data = clean_eeg.copy()\n",
    "    # Make sure it has the Cluster column from the previous section\n",
    "    if 'Cluster' not in clean_eeg_data.columns:\n",
    "        print(\"Warning: Cluster column not found. Please run the clustering section first.\")\n",
    "\n",
    "# Prepare the data for classification\n",
    "# X: features (EEG data), y: target (clusters)\n",
    "X = clean_eeg_data.iloc[:, 1:-1].values  # All columns except Time and Cluster\n",
    "y = clean_eeg_data['Cluster'].values     # Cluster column as target\n",
    "feature_names = clean_eeg_data.columns[1:-1].tolist()\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Dictionary to store model results\n",
    "model_results = {\n",
    "    'Model': [],\n",
    "    'Best Parameters': [],\n",
    "    'Training Time (s)': [],\n",
    "    'Test Accuracy': [],\n",
    "    'Cross-Val Mean': [],\n",
    "    'Cross-Val Std': []\n",
    "}\n",
    "\n",
    "# Dictionary to store feature importances\n",
    "feature_importances = {}\n",
    "\n",
    "# Function to evaluate and store model results\n",
    "def evaluate_model(model_name, model, param_grid, X_train, y_train, X_test, y_test, X, y):\n",
    "    # Create pipeline with preprocessing\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, \n",
    "        param_grid, \n",
    "        cv=5,\n",
    "        scoring='accuracy',\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Train the model and measure time\n",
    "    print(f\"\\nTraining {model_name} model with grid search...\")\n",
    "    start_time = time.time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Get the best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(best_model, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "    # Store results\n",
    "    model_results['Model'].append(model_name)\n",
    "    model_results['Best Parameters'].append(grid_search.best_params_)\n",
    "    model_results['Training Time (s)'].append(training_time)\n",
    "    model_results['Test Accuracy'].append(accuracy)\n",
    "    model_results['Cross-Val Mean'].append(cv_scores.mean())\n",
    "    model_results['Cross-Val Std'].append(cv_scores.std())\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\n{model_name} Model Evaluation:\")\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Training time: {training_time:.2f} seconds\")\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Cross-Validation Mean Accuracy: {cv_scores.mean():.4f}\")\n",
    "    print(f\"Cross-Validation Standard Deviation: {cv_scores.std():.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate feature importance\n",
    "    if hasattr(best_model.named_steps['model'], 'feature_importances_'):\n",
    "        # For tree-based models\n",
    "        importances = best_model.named_steps['model'].feature_importances_\n",
    "        feature_importances[model_name] = dict(zip(feature_names, importances))\n",
    "    else:\n",
    "        # For other models, use permutation importance\n",
    "        result = permutation_importance(\n",
    "            best_model, X_test, y_test, \n",
    "            n_repeats=10, \n",
    "            random_state=42\n",
    "        )\n",
    "        feature_importances[model_name] = dict(zip(feature_names, result.importances_mean))\n",
    "\n",
    "    # Plot top 20 features\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': list(feature_importances[model_name].values())\n",
    "    })\n",
    "    importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df.head(20))\n",
    "    plt.title(f'Top 20 EEG Features by Importance - {model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return best_model\n"
   ],
   "id": "cd3c8c5d433835d3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Random Forest Classifier\n",
   "id": "2acf9f8ecbb9db1d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define parameter grid for Random Forest\n",
    "rf_param_grid = {\n",
    "    'model__n_estimators': [100, 200],\n",
    "    'model__max_depth': [None, 10, 20],\n",
    "    'model__min_samples_split': [2, 5],\n",
    "    'model__min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Train and evaluate Random Forest model\n",
    "rf_model = evaluate_model(\n",
    "    'Random Forest',\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    rf_param_grid,\n",
    "    X_train, y_train, X_test, y_test, X, y\n",
    ")\n"
   ],
   "id": "2338950e5b53066d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Gradient Boosting Classifier\n",
   "id": "ae42ebe9c21a2e5a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Define parameter grid for Gradient Boosting\n",
    "gb_param_grid = {\n",
    "    'model__n_estimators': [100, 200],\n",
    "    'model__learning_rate': [0.01, 0.1],\n",
    "    'model__max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "# Train and evaluate Gradient Boosting model\n",
    "gb_model = evaluate_model(\n",
    "    'Gradient Boosting',\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    gb_param_grid,\n",
    "    X_train, y_train, X_test, y_test, X, y\n",
    ")\n"
   ],
   "id": "cf9303f583f3b03f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. K-Nearest Neighbors Classifier\n",
   "id": "ec70c52a0cf6894c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define parameter grid for KNN\n",
    "knn_param_grid = {\n",
    "    'model__n_neighbors': [3, 5, 7, 9],\n",
    "    'model__weights': ['uniform', 'distance'],\n",
    "    'model__metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# Train and evaluate KNN model\n",
    "knn_model = evaluate_model(\n",
    "    'K-Nearest Neighbors',\n",
    "    KNeighborsClassifier(),\n",
    "    knn_param_grid,\n",
    "    X_train, y_train, X_test, y_test, X, y\n",
    ")\n"
   ],
   "id": "8076d1bb4961b2bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Decision Tree Classifier\n",
   "id": "e29236731af96cc5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define parameter grid for Decision Tree\n",
    "dt_param_grid = {\n",
    "    'model__max_depth': [None, 10, 20, 30],\n",
    "    'model__min_samples_split': [2, 5, 10],\n",
    "    'model__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Train and evaluate Decision Tree model\n",
    "dt_model = evaluate_model(\n",
    "    'Decision Tree',\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    dt_param_grid,\n",
    "    X_train, y_train, X_test, y_test, X, y\n",
    ")\n"
   ],
   "id": "4cbf974db65e912d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Neural Network (MLP) Classifier\n",
   "id": "25d6279cd3a637fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Define parameter grid for MLP\n",
    "mlp_param_grid = {\n",
    "    'model__hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "    'model__activation': ['relu', 'tanh'],\n",
    "    'model__alpha': [0.0001, 0.001, 0.01],\n",
    "    'model__max_iter': [1000]\n",
    "}\n",
    "\n",
    "# Train and evaluate MLP model\n",
    "mlp_model = evaluate_model(\n",
    "    'Neural Network (MLP)',\n",
    "    MLPClassifier(random_state=42),\n",
    "    mlp_param_grid,\n",
    "    X_train, y_train, X_test, y_test, X, y\n",
    ")\n"
   ],
   "id": "e816d00e19dfffa7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Regression Models\n",
    "# Now we'll implement regression models to predict continuous values\n",
    "# For regression, we'll use the cluster probabilities as target values\n"
   ],
   "id": "3e7a13fa0b6636c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Get cluster probabilities from the best SVM model\n",
    "try:\n",
    "    # Check if best_model exists from SVM section\n",
    "    best_model\n",
    "    # Get cluster probabilities\n",
    "    cluster_probs = best_model.predict_proba(X)\n",
    "\n",
    "    # Create regression targets (probability of being in cluster 0)\n",
    "    y_reg = cluster_probs[:, 0]\n",
    "\n",
    "    # Split data for regression\n",
    "    X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "        X, y_reg, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Dictionary to store regression model results\n",
    "    reg_model_results = {\n",
    "        'Model': [],\n",
    "        'Best Parameters': [],\n",
    "        'Training Time (s)': [],\n",
    "        'Test R2 Score': [],\n",
    "        'Test MSE': [],\n",
    "        'Cross-Val Mean R2': [],\n",
    "        'Cross-Val Std R2': []\n",
    "    }\n",
    "\n",
    "    # Function to evaluate regression models\n",
    "    def evaluate_reg_model(model_name, model, param_grid, X_train, y_train, X_test, y_test, X, y):\n",
    "        from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "        # Create pipeline with preprocessing\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', model)\n",
    "        ])\n",
    "\n",
    "        # Perform grid search with cross-validation\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline, \n",
    "            param_grid, \n",
    "            cv=5,\n",
    "            scoring='r2',\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # Train the model and measure time\n",
    "        print(f\"\\nTraining {model_name} model with grid search...\")\n",
    "        start_time = time.time()\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        # Get the best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "        # Perform cross-validation\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(best_model, X, y, cv=cv, scoring='r2')\n",
    "\n",
    "        # Store results\n",
    "        reg_model_results['Model'].append(model_name)\n",
    "        reg_model_results['Best Parameters'].append(grid_search.best_params_)\n",
    "        reg_model_results['Training Time (s)'].append(training_time)\n",
    "        reg_model_results['Test R2 Score'].append(r2)\n",
    "        reg_model_results['Test MSE'].append(mse)\n",
    "        reg_model_results['Cross-Val Mean R2'].append(cv_scores.mean())\n",
    "        reg_model_results['Cross-Val Std R2'].append(cv_scores.std())\n",
    "\n",
    "        # Print results\n",
    "        print(f\"\\n{model_name} Model Evaluation:\")\n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "        print(f\"Training time: {training_time:.2f} seconds\")\n",
    "        print(f\"Test R2 Score: {r2:.4f}\")\n",
    "        print(f\"Test MSE: {mse:.4f}\")\n",
    "        print(f\"Cross-Validation Mean R2: {cv_scores.mean():.4f}\")\n",
    "        print(f\"Cross-Validation Standard Deviation: {cv_scores.std():.4f}\")\n",
    "\n",
    "        # Plot actual vs predicted values\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "        plt.xlabel('Actual Values')\n",
    "        plt.ylabel('Predicted Values')\n",
    "        plt.title(f'{model_name} - Actual vs Predicted')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate feature importance\n",
    "        if hasattr(best_model.named_steps['model'], 'feature_importances_'):\n",
    "            # For tree-based models\n",
    "            importances = best_model.named_steps['model'].feature_importances_\n",
    "            feature_importances[f\"{model_name} (Regression)\"] = dict(zip(feature_names, importances))\n",
    "        else:\n",
    "            # For other models, use permutation importance\n",
    "            result = permutation_importance(\n",
    "                best_model, X_test, y_test, \n",
    "                n_repeats=10, \n",
    "                random_state=42\n",
    "            )\n",
    "            feature_importances[f\"{model_name} (Regression)\"] = dict(zip(feature_names, result.importances_mean))\n",
    "\n",
    "        # Plot top 20 features\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Importance': list(feature_importances[f\"{model_name} (Regression)\"].values())\n",
    "        })\n",
    "        importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(x='Importance', y='Feature', data=importance_df.head(20))\n",
    "        plt.title(f'Top 20 EEG Features by Importance - {model_name} (Regression)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        return best_model\n",
    "\n",
    "    #%% md\n",
    "    ## 1. Linear Regression\n",
    "\n",
    "    #%%\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    # Define parameter grid for Linear Regression\n",
    "    lr_param_grid = {\n",
    "        'model__fit_intercept': [True, False],\n",
    "        'model__normalize': [True, False]\n",
    "    }\n",
    "\n",
    "    # Train and evaluate Linear Regression model\n",
    "    lr_model = evaluate_reg_model(\n",
    "        'Linear Regression',\n",
    "        LinearRegression(),\n",
    "        lr_param_grid,\n",
    "        X_train_reg, y_train_reg, X_test_reg, y_test_reg, X, y_reg\n",
    "    )\n",
    "\n",
    "    #%% md\n",
    "    ## 2. Ridge Regression\n",
    "\n",
    "    #%%\n",
    "    from sklearn.linear_model import Ridge\n",
    "\n",
    "    # Define parameter grid for Ridge Regression\n",
    "    ridge_param_grid = {\n",
    "        'model__alpha': [0.01, 0.1, 1.0, 10.0],\n",
    "        'model__fit_intercept': [True, False]\n",
    "    }\n",
    "\n",
    "    # Train and evaluate Ridge Regression model\n",
    "    ridge_model = evaluate_reg_model(\n",
    "        'Ridge Regression',\n",
    "        Ridge(random_state=42),\n",
    "        ridge_param_grid,\n",
    "        X_train_reg, y_train_reg, X_test_reg, y_test_reg, X, y_reg\n",
    "    )\n",
    "\n",
    "    #%% md\n",
    "    ## 3. Lasso Regression\n",
    "\n",
    "    #%%\n",
    "    from sklearn.linear_model import Lasso\n",
    "\n",
    "    # Define parameter grid for Lasso Regression\n",
    "    lasso_param_grid = {\n",
    "        'model__alpha': [0.001, 0.01, 0.1, 1.0],\n",
    "        'model__fit_intercept': [True, False]\n",
    "    }\n",
    "\n",
    "    # Train and evaluate Lasso Regression model\n",
    "    lasso_model = evaluate_reg_model(\n",
    "        'Lasso Regression',\n",
    "        Lasso(random_state=42, max_iter=10000),\n",
    "        lasso_param_grid,\n",
    "        X_train_reg, y_train_reg, X_test_reg, y_test_reg, X, y_reg\n",
    "    )\n",
    "\n",
    "    #%% md\n",
    "    ## 4. Support Vector Regression (SVR)\n",
    "\n",
    "    #%%\n",
    "    from sklearn.svm import SVR\n",
    "\n",
    "    # Define parameter grid for SVR\n",
    "    svr_param_grid = {\n",
    "        'model__C': [0.1, 1, 10],\n",
    "        'model__kernel': ['linear', 'rbf'],\n",
    "        'model__gamma': ['scale', 'auto']\n",
    "    }\n",
    "\n",
    "    # Train and evaluate SVR model\n",
    "    svr_model = evaluate_reg_model(\n",
    "        'Support Vector Regression',\n",
    "        SVR(),\n",
    "        svr_param_grid,\n",
    "        X_train_reg, y_train_reg, X_test_reg, y_test_reg, X, y_reg\n",
    "    )\n",
    "\n",
    "    #%% md\n",
    "    ## 5. Random Forest Regressor\n",
    "\n",
    "    #%%\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "    # Define parameter grid for Random Forest Regressor\n",
    "    rf_reg_param_grid = {\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__max_depth': [None, 10, 20],\n",
    "        'model__min_samples_split': [2, 5]\n",
    "    }\n",
    "\n",
    "    # Train and evaluate Random Forest Regressor model\n",
    "    rf_reg_model = evaluate_reg_model(\n",
    "        'Random Forest Regressor',\n",
    "        RandomForestRegressor(random_state=42),\n",
    "        rf_reg_param_grid,\n",
    "        X_train_reg, y_train_reg, X_test_reg, y_test_reg, X, y_reg\n",
    "    )\n",
    "\n",
    "except NameError:\n",
    "    print(\"Warning: SVM best_model not found. Skipping regression models.\")\n"
   ],
   "id": "f7a8bf21777bacc3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Comparison\n",
   "id": "e7ce8e0ec9dbb689"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create a DataFrame with model results\n",
    "results_df = pd.DataFrame(model_results)\n",
    "\n",
    "# Plot model accuracy comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Model', y='Test Accuracy', data=results_df)\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot training time comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Model', y='Training Time (s)', data=results_df)\n",
    "plt.title('Model Training Time Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot cross-validation results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.errorbar(\n",
    "    x=results_df['Model'],\n",
    "    y=results_df['Cross-Val Mean'],\n",
    "    yerr=results_df['Cross-Val Std'],\n",
    "    fmt='o',\n",
    "    capsize=5\n",
    ")\n",
    "plt.title('Cross-Validation Results with Standard Deviation')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance comparison across models\n",
    "# Get top 5 features from each model\n",
    "top_features = {}\n",
    "for model_name, importances in feature_importances.items():\n",
    "    if 'Regression' not in model_name:  # Only include classification models\n",
    "        sorted_importances = sorted(importances.items(), key=lambda x: x[1], reverse=True)\n",
    "        top_features[model_name] = [feature for feature, _ in sorted_importances[:5]]\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "top_features_df = pd.DataFrame(top_features)\n",
    "\n",
    "# Print top features for each model\n",
    "print(\"Top 5 Features by Model:\")\n",
    "for model, features in top_features.items():\n",
    "    print(f\"{model}: {', '.join(features)}\")\n",
    "\n",
    "# Try to display regression model results if available\n",
    "try:\n",
    "    reg_results_df = pd.DataFrame(reg_model_results)\n",
    "\n",
    "    # Plot R2 score comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='Model', y='Test R2 Score', data=reg_results_df)\n",
    "    plt.title('Regression Model R2 Score Comparison')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot MSE comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='Model', y='Test MSE', data=reg_results_df)\n",
    "    plt.title('Regression Model MSE Comparison')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except NameError:\n",
    "    print(\"Regression results not available.\")\n"
   ],
   "id": "863a676e074e3d5a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "# We've successfully implemented multiple classification and regression models to predict EEG brain states.\n",
    "# \n",
    "# Key findings:\n",
    "# 1. [Will be filled based on actual results]\n",
    "# 2. Feature importance analysis revealed which EEG channels contribute most to classification across different models\n",
    "# 3. Different models showed varying performance, with [best model] achieving the highest accuracy\n",
    "# 4. For regression tasks, [best regression model] performed best in predicting continuous values\n",
    "#\n",
    "# The comparison of multiple models provides a more robust understanding of the EEG data and helps identify\n",
    "# the most suitable approach for this specific task.\n"
   ],
   "id": "9615b7400f834e3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
